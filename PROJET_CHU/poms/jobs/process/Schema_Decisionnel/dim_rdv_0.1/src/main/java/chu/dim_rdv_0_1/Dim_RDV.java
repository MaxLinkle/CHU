// ============================================================================
//
// Copyright (c) 2006-2015, Talend Inc.
//
// This source code has been automatically generated by_Talend Open Studio for Big Data
// / Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package chu.dim_rdv_0_1;

import routines.Numeric;
import routines.DataOperation;
import routines.TalendDataGenerator;
import routines.TalendStringUtil;
import routines.TalendString;
import routines.StringHandling;
import routines.Relational;
import routines.TalendDate;
import routines.Mathematical;
import routines.system.*;
import routines.system.api.*;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;
import java.math.BigDecimal;
import java.io.ByteArrayOutputStream;
import java.io.ByteArrayInputStream;
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.ObjectOutputStream;
import java.io.ObjectInputStream;
import java.io.IOException;
import java.util.Comparator;

@SuppressWarnings("unused")

/**
 * Job: Dim_RDV Purpose: <br>
 * Description: <br>
 * 
 * @author
 * @version 7.3.1.20200219_1130
 * @status
 */
public class Dim_RDV implements TalendJob {

	protected static void logIgnoredError(String message, Throwable cause) {
		System.err.println(message);
		if (cause != null) {
			cause.printStackTrace();
		}

	}

	public final Object obj = new Object();

	// for transmiting parameters purpose
	private Object valueObject = null;

	public Object getValueObject() {
		return this.valueObject;
	}

	public void setValueObject(Object valueObject) {
		this.valueObject = valueObject;
	}

	private final static String defaultCharset = java.nio.charset.Charset.defaultCharset().name();

	private final static String utf8Charset = "UTF-8";

	// contains type for every context property
	public class PropertiesWithType extends java.util.Properties {
		private static final long serialVersionUID = 1L;
		private java.util.Map<String, String> propertyTypes = new java.util.HashMap<>();

		public PropertiesWithType(java.util.Properties properties) {
			super(properties);
		}

		public PropertiesWithType() {
			super();
		}

		public void setContextType(String key, String type) {
			propertyTypes.put(key, type);
		}

		public String getContextType(String key) {
			return propertyTypes.get(key);
		}
	}

	// create and load default properties
	private java.util.Properties defaultProps = new java.util.Properties();

	// create application properties with default
	public class ContextProperties extends PropertiesWithType {

		private static final long serialVersionUID = 1L;

		public ContextProperties(java.util.Properties properties) {
			super(properties);
		}

		public ContextProperties() {
			super();
		}

		public void synchronizeContext() {

			if (HDFS_Cluster_User != null) {

				this.setProperty("HDFS_Cluster_User", HDFS_Cluster_User.toString());

			}

			if (HDFS_Cluster_hadoopConfSpecificJar != null) {

				this.setProperty("HDFS_Cluster_hadoopConfSpecificJar", HDFS_Cluster_hadoopConfSpecificJar.toString());

			}

			if (HDFS_Cluster_NameNodeUri != null) {

				this.setProperty("HDFS_Cluster_NameNodeUri", HDFS_Cluster_NameNodeUri.toString());

			}

			if (PostgresSQL_Server != null) {

				this.setProperty("PostgresSQL_Server", PostgresSQL_Server.toString());

			}

			if (PostgresSQL_AdditionalParams != null) {

				this.setProperty("PostgresSQL_AdditionalParams", PostgresSQL_AdditionalParams.toString());

			}

			if (PostgresSQL_Schema != null) {

				this.setProperty("PostgresSQL_Schema", PostgresSQL_Schema.toString());

			}

			if (PostgresSQL_Port != null) {

				this.setProperty("PostgresSQL_Port", PostgresSQL_Port.toString());

			}

			if (PostgresSQL_Database != null) {

				this.setProperty("PostgresSQL_Database", PostgresSQL_Database.toString());

			}

			if (PostgresSQL_Login != null) {

				this.setProperty("PostgresSQL_Login", PostgresSQL_Login.toString());

			}

			if (PostgresSQL_Password != null) {

				this.setProperty("PostgresSQL_Password", PostgresSQL_Password.toString());

			}

		}

		public String HDFS_Cluster_User;

		public String getHDFS_Cluster_User() {
			return this.HDFS_Cluster_User;
		}

		public String HDFS_Cluster_hadoopConfSpecificJar;

		public String getHDFS_Cluster_hadoopConfSpecificJar() {
			return this.HDFS_Cluster_hadoopConfSpecificJar;
		}

		public String HDFS_Cluster_NameNodeUri;

		public String getHDFS_Cluster_NameNodeUri() {
			return this.HDFS_Cluster_NameNodeUri;
		}

		public String PostgresSQL_Server;

		public String getPostgresSQL_Server() {
			return this.PostgresSQL_Server;
		}

		public String PostgresSQL_AdditionalParams;

		public String getPostgresSQL_AdditionalParams() {
			return this.PostgresSQL_AdditionalParams;
		}

		public String PostgresSQL_Schema;

		public String getPostgresSQL_Schema() {
			return this.PostgresSQL_Schema;
		}

		public String PostgresSQL_Port;

		public String getPostgresSQL_Port() {
			return this.PostgresSQL_Port;
		}

		public String PostgresSQL_Database;

		public String getPostgresSQL_Database() {
			return this.PostgresSQL_Database;
		}

		public String PostgresSQL_Login;

		public String getPostgresSQL_Login() {
			return this.PostgresSQL_Login;
		}

		public java.lang.String PostgresSQL_Password;

		public java.lang.String getPostgresSQL_Password() {
			return this.PostgresSQL_Password;
		}
	}

	protected ContextProperties context = new ContextProperties(); // will be instanciated by MS.

	public ContextProperties getContext() {
		return this.context;
	}

	private final String jobVersion = "0.1";
	private final String jobName = "Dim_RDV";
	private final String projectName = "CHU";
	public Integer errorCode = null;
	private String currentComponent = "";

	private final java.util.Map<String, Object> globalMap = new java.util.HashMap<String, Object>();
	private final static java.util.Map<String, Object> junitGlobalMap = new java.util.HashMap<String, Object>();

	private final java.util.Map<String, Long> start_Hash = new java.util.HashMap<String, Long>();
	private final java.util.Map<String, Long> end_Hash = new java.util.HashMap<String, Long>();
	private final java.util.Map<String, Boolean> ok_Hash = new java.util.HashMap<String, Boolean>();
	public final java.util.List<String[]> globalBuffer = new java.util.ArrayList<String[]>();

	private RunStat runStat = new RunStat();

	// OSGi DataSource
	private final static String KEY_DB_DATASOURCES = "KEY_DB_DATASOURCES";

	private final static String KEY_DB_DATASOURCES_RAW = "KEY_DB_DATASOURCES_RAW";

	public void setDataSources(java.util.Map<String, javax.sql.DataSource> dataSources) {
		java.util.Map<String, routines.system.TalendDataSource> talendDataSources = new java.util.HashMap<String, routines.system.TalendDataSource>();
		for (java.util.Map.Entry<String, javax.sql.DataSource> dataSourceEntry : dataSources.entrySet()) {
			talendDataSources.put(dataSourceEntry.getKey(),
					new routines.system.TalendDataSource(dataSourceEntry.getValue()));
		}
		globalMap.put(KEY_DB_DATASOURCES, talendDataSources);
		globalMap.put(KEY_DB_DATASOURCES_RAW, new java.util.HashMap<String, javax.sql.DataSource>(dataSources));
	}

	private final java.io.ByteArrayOutputStream baos = new java.io.ByteArrayOutputStream();
	private final java.io.PrintStream errorMessagePS = new java.io.PrintStream(new java.io.BufferedOutputStream(baos));

	public String getExceptionStackTrace() {
		if ("failure".equals(this.getStatus())) {
			errorMessagePS.flush();
			return baos.toString();
		}
		return null;
	}

	private Exception exception;

	public Exception getException() {
		if ("failure".equals(this.getStatus())) {
			return this.exception;
		}
		return null;
	}

	private class TalendException extends Exception {

		private static final long serialVersionUID = 1L;

		private java.util.Map<String, Object> globalMap = null;
		private Exception e = null;
		private String currentComponent = null;
		private String virtualComponentName = null;

		public void setVirtualComponentName(String virtualComponentName) {
			this.virtualComponentName = virtualComponentName;
		}

		private TalendException(Exception e, String errorComponent, final java.util.Map<String, Object> globalMap) {
			this.currentComponent = errorComponent;
			this.globalMap = globalMap;
			this.e = e;
		}

		public Exception getException() {
			return this.e;
		}

		public String getCurrentComponent() {
			return this.currentComponent;
		}

		public String getExceptionCauseMessage(Exception e) {
			Throwable cause = e;
			String message = null;
			int i = 10;
			while (null != cause && 0 < i--) {
				message = cause.getMessage();
				if (null == message) {
					cause = cause.getCause();
				} else {
					break;
				}
			}
			if (null == message) {
				message = e.getClass().getName();
			}
			return message;
		}

		@Override
		public void printStackTrace() {
			if (!(e instanceof TalendException || e instanceof TDieException)) {
				if (virtualComponentName != null && currentComponent.indexOf(virtualComponentName + "_") == 0) {
					globalMap.put(virtualComponentName + "_ERROR_MESSAGE", getExceptionCauseMessage(e));
				}
				globalMap.put(currentComponent + "_ERROR_MESSAGE", getExceptionCauseMessage(e));
				System.err.println("Exception in component " + currentComponent + " (" + jobName + ")");
			}
			if (!(e instanceof TDieException)) {
				if (e instanceof TalendException) {
					e.printStackTrace();
				} else {
					e.printStackTrace();
					e.printStackTrace(errorMessagePS);
					Dim_RDV.this.exception = e;
				}
			}
			if (!(e instanceof TalendException)) {
				try {
					for (java.lang.reflect.Method m : this.getClass().getEnclosingClass().getMethods()) {
						if (m.getName().compareTo(currentComponent + "_error") == 0) {
							m.invoke(Dim_RDV.this, new Object[] { e, currentComponent, globalMap });
							break;
						}
					}

					if (!(e instanceof TDieException)) {
					}
				} catch (Exception e) {
					this.e.printStackTrace();
				}
			}
		}
	}

	public void tDBConnection_2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBConnection_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHDFSConnection_2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHDFSConnection_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tDBInput_2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tMap_1_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap)
			throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHDFSOutput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tLogRow_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBInput_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tDBClose_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tDBClose_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHDFSConnection_2_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHDFSConnection_2_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tHadoopConfManager_tHDFSOutput_1_error(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		end_Hash.put(errorComponent, System.currentTimeMillis());

		status = "failure";

		tHadoopConfManager_tHDFSOutput_1_onSubJobError(exception, errorComponent, globalMap);
	}

	public void tDBConnection_2_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHDFSConnection_2_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tDBInput_2_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tDBClose_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHDFSConnection_2_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tHadoopConfManager_tHDFSOutput_1_onSubJobError(Exception exception, String errorComponent,
			final java.util.Map<String, Object> globalMap) throws TalendException {

		resumeUtil.addLog("SYSTEM_LOG", "NODE:" + errorComponent, "", Thread.currentThread().getId() + "", "FATAL", "",
				exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception), "");

	}

	public void tDBConnection_2Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tDBConnection_2_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tDBConnection_2 begin ] start
				 */

				ok_Hash.put("tDBConnection_2", false);
				start_Hash.put("tDBConnection_2", System.currentTimeMillis());

				currentComponent = "tDBConnection_2";

				int tos_count_tDBConnection_2 = 0;

				String dbProperties_tDBConnection_2 = context.PostgresSQL_AdditionalParams;
				String url_tDBConnection_2 = "jdbc:postgresql://" + context.PostgresSQL_Server + ":"
						+ context.PostgresSQL_Port + "/" + context.PostgresSQL_Database;

				if (dbProperties_tDBConnection_2 != null && !"".equals(dbProperties_tDBConnection_2.trim())) {
					url_tDBConnection_2 = url_tDBConnection_2 + "?" + dbProperties_tDBConnection_2;
				}
				String dbUser_tDBConnection_2 = context.PostgresSQL_Login;

				final String decryptedPassword_tDBConnection_2 = context.PostgresSQL_Password;
				String dbPwd_tDBConnection_2 = decryptedPassword_tDBConnection_2;

				java.sql.Connection conn_tDBConnection_2 = null;

				java.util.Enumeration<java.sql.Driver> drivers_tDBConnection_2 = java.sql.DriverManager.getDrivers();
				java.util.Set<String> redShiftDriverNames_tDBConnection_2 = new java.util.HashSet<String>(
						java.util.Arrays.asList("com.amazon.redshift.jdbc.Driver", "com.amazon.redshift.jdbc41.Driver",
								"com.amazon.redshift.jdbc42.Driver"));
				while (drivers_tDBConnection_2.hasMoreElements()) {
					java.sql.Driver d_tDBConnection_2 = drivers_tDBConnection_2.nextElement();
					if (redShiftDriverNames_tDBConnection_2.contains(d_tDBConnection_2.getClass().getName())) {
						try {
							java.sql.DriverManager.deregisterDriver(d_tDBConnection_2);
							java.sql.DriverManager.registerDriver(d_tDBConnection_2);
						} catch (java.lang.Exception e_tDBConnection_2) {
							// do nothing
						}
					}
				}
				String driverClass_tDBConnection_2 = "org.postgresql.Driver";
				java.lang.Class jdbcclazz_tDBConnection_2 = java.lang.Class.forName(driverClass_tDBConnection_2);
				globalMap.put("driverClass_tDBConnection_2", driverClass_tDBConnection_2);

				conn_tDBConnection_2 = java.sql.DriverManager.getConnection(url_tDBConnection_2, dbUser_tDBConnection_2,
						dbPwd_tDBConnection_2);

				globalMap.put("conn_tDBConnection_2", conn_tDBConnection_2);
				if (null != conn_tDBConnection_2) {

					conn_tDBConnection_2.setAutoCommit(false);
				}

				globalMap.put("schema_" + "tDBConnection_2", context.PostgresSQL_Schema);

				globalMap.put("conn_" + "tDBConnection_2", conn_tDBConnection_2);

				/**
				 * [tDBConnection_2 begin ] stop
				 */

				/**
				 * [tDBConnection_2 main ] start
				 */

				currentComponent = "tDBConnection_2";

				tos_count_tDBConnection_2++;

				/**
				 * [tDBConnection_2 main ] stop
				 */

				/**
				 * [tDBConnection_2 process_data_begin ] start
				 */

				currentComponent = "tDBConnection_2";

				/**
				 * [tDBConnection_2 process_data_begin ] stop
				 */

				/**
				 * [tDBConnection_2 process_data_end ] start
				 */

				currentComponent = "tDBConnection_2";

				/**
				 * [tDBConnection_2 process_data_end ] stop
				 */

				/**
				 * [tDBConnection_2 end ] start
				 */

				currentComponent = "tDBConnection_2";

				ok_Hash.put("tDBConnection_2", true);
				end_Hash.put("tDBConnection_2", System.currentTimeMillis());

				/**
				 * [tDBConnection_2 end ] stop
				 */
			} // end the resume

			if (resumeEntryMethodName == null || globalResumeTicket) {
				resumeUtil.addLog("CHECKPOINT", "CONNECTION:SUBJOB_OK:tDBConnection_2:OnSubjobOk", "",
						Thread.currentThread().getId() + "", "", "", "", "", "");
			}

			if (execStat) {
				runStat.updateStatOnConnection("OnSubjobOk3", 0, "ok");
			}

			tHDFSConnection_2Process(globalMap);

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tDBConnection_2 finally ] start
				 */

				currentComponent = "tDBConnection_2";

				/**
				 * [tDBConnection_2 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tDBConnection_2_SUBPROCESS_STATE", 1);
	}

	public void tHDFSConnection_2Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tHDFSConnection_2_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHDFSConnection_2 begin ] start
				 */

				ok_Hash.put("tHDFSConnection_2", false);
				start_Hash.put("tHDFSConnection_2", System.currentTimeMillis());

				currentComponent = "tHDFSConnection_2";

				int tos_count_tHDFSConnection_2 = 0;

				org.apache.hadoop.conf.Configuration conf_tHDFSConnection_2 = new org.apache.hadoop.conf.Configuration();
				conf_tHDFSConnection_2.set("fs.default.name", context.HDFS_Cluster_NameNodeUri);
				conf_tHDFSConnection_2.set("fs.default.name", context.HDFS_Cluster_NameNodeUri);

				conf_tHDFSConnection_2.set("dfs.client.use.datanode.hostname", "true");

				org.apache.hadoop.security.UserGroupInformation.setConfiguration(conf_tHDFSConnection_2);
				globalMap.put("conn_tHDFSConnection_2", conf_tHDFSConnection_2);

				/**
				 * [tHDFSConnection_2 begin ] stop
				 */

				/**
				 * [tHDFSConnection_2 main ] start
				 */

				currentComponent = "tHDFSConnection_2";

				tos_count_tHDFSConnection_2++;

				/**
				 * [tHDFSConnection_2 main ] stop
				 */

				/**
				 * [tHDFSConnection_2 process_data_begin ] start
				 */

				currentComponent = "tHDFSConnection_2";

				/**
				 * [tHDFSConnection_2 process_data_begin ] stop
				 */

				/**
				 * [tHDFSConnection_2 process_data_end ] start
				 */

				currentComponent = "tHDFSConnection_2";

				/**
				 * [tHDFSConnection_2 process_data_end ] stop
				 */

				/**
				 * [tHDFSConnection_2 end ] start
				 */

				currentComponent = "tHDFSConnection_2";

				ok_Hash.put("tHDFSConnection_2", true);
				end_Hash.put("tHDFSConnection_2", System.currentTimeMillis());

				/**
				 * [tHDFSConnection_2 end ] stop
				 */
			} // end the resume

			if (resumeEntryMethodName == null || globalResumeTicket) {
				resumeUtil.addLog("CHECKPOINT", "CONNECTION:SUBJOB_OK:tHDFSConnection_2:OnSubjobOk", "",
						Thread.currentThread().getId() + "", "", "", "", "", "");
			}

			if (execStat) {
				runStat.updateStatOnConnection("OnSubjobOk4", 0, "ok");
			}

			tDBInput_2Process(globalMap);

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHDFSConnection_2 finally ] start
				 */

				currentComponent = "tHDFSConnection_2";

				/**
				 * [tHDFSConnection_2 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHDFSConnection_2_SUBPROCESS_STATE", 1);
	}

	public static class row2Struct implements routines.system.IPersistableRow<row2Struct> {
		final static byte[] commonByteArrayLock_CHU_Dim_RDV = new byte[0];
		static byte[] commonByteArray_CHU_Dim_RDV = new byte[0];

		public int Num_consultation;

		public int getNum_consultation() {
			return this.Num_consultation;
		}

		public String Date_RDV;

		public String getDate_RDV() {
			return this.Date_RDV;
		}

		public String Heure_debut;

		public String getHeure_debut() {
			return this.Heure_debut;
		}

		public String Heure_fin;

		public String getHeure_fin() {
			return this.Heure_fin;
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_CHU_Dim_RDV.length) {
					if (length < 1024 && commonByteArray_CHU_Dim_RDV.length == 0) {
						commonByteArray_CHU_Dim_RDV = new byte[1024];
					} else {
						commonByteArray_CHU_Dim_RDV = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_CHU_Dim_RDV, 0, length);
				strReturn = new String(commonByteArray_CHU_Dim_RDV, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_CHU_Dim_RDV) {

				try {

					int length = 0;

					this.Num_consultation = dis.readInt();

					this.Date_RDV = readString(dis);

					this.Heure_debut = readString(dis);

					this.Heure_fin = readString(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// int

				dos.writeInt(this.Num_consultation);

				// String

				writeString(this.Date_RDV, dos);

				// String

				writeString(this.Heure_debut, dos);

				// String

				writeString(this.Heure_fin, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Num_consultation=" + String.valueOf(Num_consultation));
			sb.append(",Date_RDV=" + Date_RDV);
			sb.append(",Heure_debut=" + Heure_debut);
			sb.append(",Heure_fin=" + Heure_fin);
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row2Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class rdvStruct implements routines.system.IPersistableRow<rdvStruct> {
		final static byte[] commonByteArrayLock_CHU_Dim_RDV = new byte[0];
		static byte[] commonByteArray_CHU_Dim_RDV = new byte[0];

		public int Num_consultation;

		public int getNum_consultation() {
			return this.Num_consultation;
		}

		public String Date_RDV;

		public String getDate_RDV() {
			return this.Date_RDV;
		}

		public String Heure_debut;

		public String getHeure_debut() {
			return this.Heure_debut;
		}

		public String Heure_fin;

		public String getHeure_fin() {
			return this.Heure_fin;
		}

		private String readString(ObjectInputStream dis) throws IOException {
			String strReturn = null;
			int length = 0;
			length = dis.readInt();
			if (length == -1) {
				strReturn = null;
			} else {
				if (length > commonByteArray_CHU_Dim_RDV.length) {
					if (length < 1024 && commonByteArray_CHU_Dim_RDV.length == 0) {
						commonByteArray_CHU_Dim_RDV = new byte[1024];
					} else {
						commonByteArray_CHU_Dim_RDV = new byte[2 * length];
					}
				}
				dis.readFully(commonByteArray_CHU_Dim_RDV, 0, length);
				strReturn = new String(commonByteArray_CHU_Dim_RDV, 0, length, utf8Charset);
			}
			return strReturn;
		}

		private void writeString(String str, ObjectOutputStream dos) throws IOException {
			if (str == null) {
				dos.writeInt(-1);
			} else {
				byte[] byteArray = str.getBytes(utf8Charset);
				dos.writeInt(byteArray.length);
				dos.write(byteArray);
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_CHU_Dim_RDV) {

				try {

					int length = 0;

					this.Num_consultation = dis.readInt();

					this.Date_RDV = readString(dis);

					this.Heure_debut = readString(dis);

					this.Heure_fin = readString(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// int

				dos.writeInt(this.Num_consultation);

				// String

				writeString(this.Date_RDV, dos);

				// String

				writeString(this.Heure_debut, dos);

				// String

				writeString(this.Heure_fin, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Num_consultation=" + String.valueOf(Num_consultation));
			sb.append(",Date_RDV=" + Date_RDV);
			sb.append(",Heure_debut=" + Heure_debut);
			sb.append(",Heure_fin=" + Heure_fin);
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(rdvStruct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public static class row1Struct implements routines.system.IPersistableRow<row1Struct> {
		final static byte[] commonByteArrayLock_CHU_Dim_RDV = new byte[0];
		static byte[] commonByteArray_CHU_Dim_RDV = new byte[0];

		public int Num_consultation;

		public int getNum_consultation() {
			return this.Num_consultation;
		}

		public java.util.Date Date_RDV;

		public java.util.Date getDate_RDV() {
			return this.Date_RDV;
		}

		public java.util.Date Heure_debut;

		public java.util.Date getHeure_debut() {
			return this.Heure_debut;
		}

		public java.util.Date Heure_fin;

		public java.util.Date getHeure_fin() {
			return this.Heure_fin;
		}

		private java.util.Date readDate(ObjectInputStream dis) throws IOException {
			java.util.Date dateReturn = null;
			int length = 0;
			length = dis.readByte();
			if (length == -1) {
				dateReturn = null;
			} else {
				dateReturn = new Date(dis.readLong());
			}
			return dateReturn;
		}

		private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException {
			if (date1 == null) {
				dos.writeByte(-1);
			} else {
				dos.writeByte(0);
				dos.writeLong(date1.getTime());
			}
		}

		public void readData(ObjectInputStream dis) {

			synchronized (commonByteArrayLock_CHU_Dim_RDV) {

				try {

					int length = 0;

					this.Num_consultation = dis.readInt();

					this.Date_RDV = readDate(dis);

					this.Heure_debut = readDate(dis);

					this.Heure_fin = readDate(dis);

				} catch (IOException e) {
					throw new RuntimeException(e);

				}

			}

		}

		public void writeData(ObjectOutputStream dos) {
			try {

				// int

				dos.writeInt(this.Num_consultation);

				// java.util.Date

				writeDate(this.Date_RDV, dos);

				// java.util.Date

				writeDate(this.Heure_debut, dos);

				// java.util.Date

				writeDate(this.Heure_fin, dos);

			} catch (IOException e) {
				throw new RuntimeException(e);
			}

		}

		public String toString() {

			StringBuilder sb = new StringBuilder();
			sb.append(super.toString());
			sb.append("[");
			sb.append("Num_consultation=" + String.valueOf(Num_consultation));
			sb.append(",Date_RDV=" + String.valueOf(Date_RDV));
			sb.append(",Heure_debut=" + String.valueOf(Heure_debut));
			sb.append(",Heure_fin=" + String.valueOf(Heure_fin));
			sb.append("]");

			return sb.toString();
		}

		/**
		 * Compare keys
		 */
		public int compareTo(row1Struct other) {

			int returnValue = -1;

			return returnValue;
		}

		private int checkNullsAndCompare(Object object1, Object object2) {
			int returnValue = 0;
			if (object1 instanceof Comparable && object2 instanceof Comparable) {
				returnValue = ((Comparable) object1).compareTo(object2);
			} else if (object1 != null && object2 != null) {
				returnValue = compareStrings(object1.toString(), object2.toString());
			} else if (object1 == null && object2 != null) {
				returnValue = 1;
			} else if (object1 != null && object2 == null) {
				returnValue = -1;
			} else {
				returnValue = 0;
			}

			return returnValue;
		}

		private int compareStrings(String string1, String string2) {
			return string1.compareTo(string2);
		}

	}

	public void tDBInput_2Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tDBInput_2_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				row1Struct row1 = new row1Struct();
				rdvStruct rdv = new rdvStruct();
				rdvStruct row2 = rdv;

				/**
				 * [tLogRow_1 begin ] start
				 */

				ok_Hash.put("tLogRow_1", false);
				start_Hash.put("tLogRow_1", System.currentTimeMillis());

				currentComponent = "tLogRow_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row2");
				}

				int tos_count_tLogRow_1 = 0;

				///////////////////////

				class Util_tLogRow_1 {

					String[] des_top = { ".", ".", "-", "+" };

					String[] des_head = { "|=", "=|", "-", "+" };

					String[] des_bottom = { "'", "'", "-", "+" };

					String name = "";

					java.util.List<String[]> list = new java.util.ArrayList<String[]>();

					int[] colLengths = new int[4];

					public void addRow(String[] row) {

						for (int i = 0; i < 4; i++) {
							if (row[i] != null) {
								colLengths[i] = Math.max(colLengths[i], row[i].length());
							}
						}
						list.add(row);
					}

					public void setTableName(String name) {

						this.name = name;
					}

					public StringBuilder format() {

						StringBuilder sb = new StringBuilder();

						sb.append(print(des_top));

						int totals = 0;
						for (int i = 0; i < colLengths.length; i++) {
							totals = totals + colLengths[i];
						}

						// name
						sb.append("|");
						int k = 0;
						for (k = 0; k < (totals + 3 - name.length()) / 2; k++) {
							sb.append(' ');
						}
						sb.append(name);
						for (int i = 0; i < totals + 3 - name.length() - k; i++) {
							sb.append(' ');
						}
						sb.append("|\n");

						// head and rows
						sb.append(print(des_head));
						for (int i = 0; i < list.size(); i++) {

							String[] row = list.get(i);

							java.util.Formatter formatter = new java.util.Formatter(new StringBuilder());

							StringBuilder sbformat = new StringBuilder();
							sbformat.append("|%1$-");
							sbformat.append(colLengths[0]);
							sbformat.append("s");

							sbformat.append("|%2$-");
							sbformat.append(colLengths[1]);
							sbformat.append("s");

							sbformat.append("|%3$-");
							sbformat.append(colLengths[2]);
							sbformat.append("s");

							sbformat.append("|%4$-");
							sbformat.append(colLengths[3]);
							sbformat.append("s");

							sbformat.append("|\n");

							formatter.format(sbformat.toString(), (Object[]) row);

							sb.append(formatter.toString());
							if (i == 0)
								sb.append(print(des_head)); // print the head
						}

						// end
						sb.append(print(des_bottom));
						return sb;
					}

					private StringBuilder print(String[] fillChars) {
						StringBuilder sb = new StringBuilder();
						// first column
						sb.append(fillChars[0]);
						for (int i = 0; i < colLengths[0] - fillChars[0].length() + 1; i++) {
							sb.append(fillChars[2]);
						}
						sb.append(fillChars[3]);

						for (int i = 0; i < colLengths[1] - fillChars[3].length() + 1; i++) {
							sb.append(fillChars[2]);
						}
						sb.append(fillChars[3]);
						for (int i = 0; i < colLengths[2] - fillChars[3].length() + 1; i++) {
							sb.append(fillChars[2]);
						}
						sb.append(fillChars[3]);

						// last column
						for (int i = 0; i < colLengths[3] - fillChars[1].length() + 1; i++) {
							sb.append(fillChars[2]);
						}
						sb.append(fillChars[1]);
						sb.append("\n");
						return sb;
					}

					public boolean isTableEmpty() {
						if (list.size() > 1)
							return false;
						return true;
					}
				}
				Util_tLogRow_1 util_tLogRow_1 = new Util_tLogRow_1();
				util_tLogRow_1.setTableName("tLogRow_1");
				util_tLogRow_1.addRow(new String[] { "Num_consultation", "Date_RDV", "Heure_debut", "Heure_fin", });
				StringBuilder strBuffer_tLogRow_1 = null;
				int nb_line_tLogRow_1 = 0;
///////////////////////    			

				/**
				 * [tLogRow_1 begin ] stop
				 */

				/**
				 * [tHDFSOutput_1 begin ] start
				 */

				ok_Hash.put("tHDFSOutput_1", false);
				start_Hash.put("tHDFSOutput_1", System.currentTimeMillis());

				currentComponent = "tHDFSOutput_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "rdv");
				}

				int tos_count_tHDFSOutput_1 = 0;

				String username_tHDFSOutput_1 = "";
				org.apache.hadoop.fs.FileSystem fs_tHDFSOutput_1 = null;
				org.apache.hadoop.conf.Configuration conf_tHDFSOutput_1 = new org.apache.hadoop.conf.Configuration();

				conf_tHDFSOutput_1.set("fs.default.name", context.HDFS_Cluster_NameNodeUri);

				conf_tHDFSOutput_1.set("dfs.client.use.datanode.hostname", "true");

				org.apache.hadoop.security.UserGroupInformation.setConfiguration(conf_tHDFSOutput_1);
				username_tHDFSOutput_1 = "cloudera";
				if (username_tHDFSOutput_1 == null || "".equals(username_tHDFSOutput_1)) {
					fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(conf_tHDFSOutput_1);
				} else {
					System.setProperty("HADOOP_USER_NAME", username_tHDFSOutput_1);
					fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(
							new java.net.URI(conf_tHDFSOutput_1.get("fs.default.name")), conf_tHDFSOutput_1,
							username_tHDFSOutput_1);
				}

				org.apache.hadoop.fs.Path path_tHDFSOutput_1 = new org.apache.hadoop.fs.Path(
						"/user/cloudera/CHU/Dim_RDV/Dim_RDV.txt");
				int nb_line_tHDFSOutput_1 = 0;

				org.apache.hadoop.fs.FSDataOutputStream fsDataOutputStream_tHDFSOutput_1 = null;

				fsDataOutputStream_tHDFSOutput_1 = fs_tHDFSOutput_1.create(path_tHDFSOutput_1, true);

				java.io.Writer outtHDFSOutput_1 = null;
				outtHDFSOutput_1 = new java.io.BufferedWriter(
						new java.io.OutputStreamWriter(fsDataOutputStream_tHDFSOutput_1));

				/**
				 * [tHDFSOutput_1 begin ] stop
				 */

				/**
				 * [tMap_1 begin ] start
				 */

				ok_Hash.put("tMap_1", false);
				start_Hash.put("tMap_1", System.currentTimeMillis());

				currentComponent = "tMap_1";

				if (execStat) {
					runStat.updateStatOnConnection(resourceMap, iterateId, 0, 0, "row1");
				}

				int tos_count_tMap_1 = 0;

// ###############################
// # Lookup's keys initialization
// ###############################        

// ###############################
// # Vars initialization
				class Var__tMap_1__Struct {
					String TrimDate;
					String TrimHeureDebut;
					String TrimHeureFin;
				}
				Var__tMap_1__Struct Var__tMap_1 = new Var__tMap_1__Struct();
// ###############################

// ###############################
// # Outputs initialization
				rdvStruct rdv_tmp = new rdvStruct();
// ###############################

				/**
				 * [tMap_1 begin ] stop
				 */

				/**
				 * [tDBInput_2 begin ] start
				 */

				ok_Hash.put("tDBInput_2", false);
				start_Hash.put("tDBInput_2", System.currentTimeMillis());

				currentComponent = "tDBInput_2";

				int tos_count_tDBInput_2 = 0;

				int nb_line_tDBInput_2 = 0;
				java.sql.Connection conn_tDBInput_2 = null;
				String driverClass_tDBInput_2 = "org.postgresql.Driver";
				java.lang.Class jdbcclazz_tDBInput_2 = java.lang.Class.forName(driverClass_tDBInput_2);
				String dbUser_tDBInput_2 = context.PostgresSQL_Login;

				final String decryptedPassword_tDBInput_2 = context.PostgresSQL_Password;

				String dbPwd_tDBInput_2 = decryptedPassword_tDBInput_2;

				String url_tDBInput_2 = "jdbc:postgresql://" + context.PostgresSQL_Server + ":"
						+ context.PostgresSQL_Port + "/" + context.PostgresSQL_Database + "?"
						+ context.PostgresSQL_AdditionalParams;

				conn_tDBInput_2 = java.sql.DriverManager.getConnection(url_tDBInput_2, dbUser_tDBInput_2,
						dbPwd_tDBInput_2);

				conn_tDBInput_2.setAutoCommit(false);

				java.sql.Statement stmt_tDBInput_2 = conn_tDBInput_2.createStatement();

				String dbquery_tDBInput_2 = "SELECT \"Num_consultation\", \"Date\" as \"Date_RDV\",  \"Heure_debut\", \"Heure_fin\" FROM public.\"Consultation\"";

				globalMap.put("tDBInput_2_QUERY", dbquery_tDBInput_2);
				java.sql.ResultSet rs_tDBInput_2 = null;

				try {
					rs_tDBInput_2 = stmt_tDBInput_2.executeQuery(dbquery_tDBInput_2);
					java.sql.ResultSetMetaData rsmd_tDBInput_2 = rs_tDBInput_2.getMetaData();
					int colQtyInRs_tDBInput_2 = rsmd_tDBInput_2.getColumnCount();

					String tmpContent_tDBInput_2 = null;

					while (rs_tDBInput_2.next()) {
						nb_line_tDBInput_2++;

						if (colQtyInRs_tDBInput_2 < 1) {
							row1.Num_consultation = 0;
						} else {

							row1.Num_consultation = rs_tDBInput_2.getInt(1);
							if (rs_tDBInput_2.wasNull()) {
								throw new RuntimeException("Null value in non-Nullable column");
							}
						}
						if (colQtyInRs_tDBInput_2 < 2) {
							row1.Date_RDV = null;
						} else {

							row1.Date_RDV = routines.system.JDBCUtil.getDate(rs_tDBInput_2, 2);
						}
						if (colQtyInRs_tDBInput_2 < 3) {
							row1.Heure_debut = null;
						} else {

							row1.Heure_debut = routines.system.JDBCUtil.getDate(rs_tDBInput_2, 3);
						}
						if (colQtyInRs_tDBInput_2 < 4) {
							row1.Heure_fin = null;
						} else {

							row1.Heure_fin = routines.system.JDBCUtil.getDate(rs_tDBInput_2, 4);
						}

						/**
						 * [tDBInput_2 begin ] stop
						 */

						/**
						 * [tDBInput_2 main ] start
						 */

						currentComponent = "tDBInput_2";

						tos_count_tDBInput_2++;

						/**
						 * [tDBInput_2 main ] stop
						 */

						/**
						 * [tDBInput_2 process_data_begin ] start
						 */

						currentComponent = "tDBInput_2";

						/**
						 * [tDBInput_2 process_data_begin ] stop
						 */

						/**
						 * [tMap_1 main ] start
						 */

						currentComponent = "tMap_1";

						if (execStat) {
							runStat.updateStatOnConnection(iterateId, 1, 1, "row1");
						}

						boolean hasCasePrimitiveKeyWithNull_tMap_1 = false;

						// ###############################
						// # Input tables (lookups)
						boolean rejectedInnerJoin_tMap_1 = false;
						boolean mainRowRejected_tMap_1 = false;

						// ###############################
						{ // start of Var scope

							// ###############################
							// # Vars tables

							Var__tMap_1__Struct Var = Var__tMap_1;
							Var.TrimDate = TalendDate.formatDate("yyyy-MM-dd", row1.Date_RDV);
							Var.TrimHeureDebut = TalendDate.formatDate("HH:mm:ss", row1.Heure_debut);
							Var.TrimHeureFin = TalendDate.formatDate("HH:mm:ss", row1.Heure_fin);// ###############################
							// ###############################
							// # Output tables

							rdv = null;

// # Output table : 'rdv'
							rdv_tmp.Num_consultation = row1.Num_consultation;
							rdv_tmp.Date_RDV = Var.TrimDate;
							rdv_tmp.Heure_debut = Var.TrimHeureDebut;
							rdv_tmp.Heure_fin = Var.TrimHeureFin;
							rdv = rdv_tmp;
// ###############################

						} // end of Var scope

						rejectedInnerJoin_tMap_1 = false;

						tos_count_tMap_1++;

						/**
						 * [tMap_1 main ] stop
						 */

						/**
						 * [tMap_1 process_data_begin ] start
						 */

						currentComponent = "tMap_1";

						/**
						 * [tMap_1 process_data_begin ] stop
						 */
// Start of branch "rdv"
						if (rdv != null) {

							/**
							 * [tHDFSOutput_1 main ] start
							 */

							currentComponent = "tHDFSOutput_1";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "rdv");
							}

							StringBuilder sb_tHDFSOutput_1 = new StringBuilder();

							sb_tHDFSOutput_1.append(

									rdv.Num_consultation

							);

							sb_tHDFSOutput_1.append(";");

							if (rdv.Date_RDV != null) {

								sb_tHDFSOutput_1.append(

										rdv.Date_RDV

								);

							}

							sb_tHDFSOutput_1.append(";");

							if (rdv.Heure_debut != null) {

								sb_tHDFSOutput_1.append(

										rdv.Heure_debut

								);

							}

							sb_tHDFSOutput_1.append(";");

							if (rdv.Heure_fin != null) {

								sb_tHDFSOutput_1.append(

										rdv.Heure_fin

								);

							}

							sb_tHDFSOutput_1.append("\n");

							outtHDFSOutput_1.write(sb_tHDFSOutput_1.toString());

							nb_line_tHDFSOutput_1++;

							row2 = rdv;

							tos_count_tHDFSOutput_1++;

							/**
							 * [tHDFSOutput_1 main ] stop
							 */

							/**
							 * [tHDFSOutput_1 process_data_begin ] start
							 */

							currentComponent = "tHDFSOutput_1";

							/**
							 * [tHDFSOutput_1 process_data_begin ] stop
							 */

							/**
							 * [tLogRow_1 main ] start
							 */

							currentComponent = "tLogRow_1";

							if (execStat) {
								runStat.updateStatOnConnection(iterateId, 1, 1, "row2");
							}

///////////////////////		

							String[] row_tLogRow_1 = new String[4];

							row_tLogRow_1[0] = String.valueOf(row2.Num_consultation);

							if (row2.Date_RDV != null) { //
								row_tLogRow_1[1] = String.valueOf(row2.Date_RDV);

							} //

							if (row2.Heure_debut != null) { //
								row_tLogRow_1[2] = String.valueOf(row2.Heure_debut);

							} //

							if (row2.Heure_fin != null) { //
								row_tLogRow_1[3] = String.valueOf(row2.Heure_fin);

							} //

							util_tLogRow_1.addRow(row_tLogRow_1);
							nb_line_tLogRow_1++;
//////

//////                    

///////////////////////    			

							tos_count_tLogRow_1++;

							/**
							 * [tLogRow_1 main ] stop
							 */

							/**
							 * [tLogRow_1 process_data_begin ] start
							 */

							currentComponent = "tLogRow_1";

							/**
							 * [tLogRow_1 process_data_begin ] stop
							 */

							/**
							 * [tLogRow_1 process_data_end ] start
							 */

							currentComponent = "tLogRow_1";

							/**
							 * [tLogRow_1 process_data_end ] stop
							 */

							/**
							 * [tHDFSOutput_1 process_data_end ] start
							 */

							currentComponent = "tHDFSOutput_1";

							/**
							 * [tHDFSOutput_1 process_data_end ] stop
							 */

						} // End of branch "rdv"

						/**
						 * [tMap_1 process_data_end ] start
						 */

						currentComponent = "tMap_1";

						/**
						 * [tMap_1 process_data_end ] stop
						 */

						/**
						 * [tDBInput_2 process_data_end ] start
						 */

						currentComponent = "tDBInput_2";

						/**
						 * [tDBInput_2 process_data_end ] stop
						 */

						/**
						 * [tDBInput_2 end ] start
						 */

						currentComponent = "tDBInput_2";

					}
				} finally {
					if (rs_tDBInput_2 != null) {
						rs_tDBInput_2.close();
					}
					if (stmt_tDBInput_2 != null) {
						stmt_tDBInput_2.close();
					}
					if (conn_tDBInput_2 != null && !conn_tDBInput_2.isClosed()) {

						conn_tDBInput_2.commit();

						conn_tDBInput_2.close();

						if ("com.mysql.cj.jdbc.Driver".equals((String) globalMap.get("driverClass_"))
								&& routines.system.BundleUtils.inOSGi()) {
							Class.forName("com.mysql.cj.jdbc.AbandonedConnectionCleanupThread")
									.getMethod("checkedShutdown").invoke(null, (Object[]) null);
						}

					}

				}
				globalMap.put("tDBInput_2_NB_LINE", nb_line_tDBInput_2);

				ok_Hash.put("tDBInput_2", true);
				end_Hash.put("tDBInput_2", System.currentTimeMillis());

				/**
				 * [tDBInput_2 end ] stop
				 */

				/**
				 * [tMap_1 end ] start
				 */

				currentComponent = "tMap_1";

// ###############################
// # Lookup hashes releasing
// ###############################      

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row1");
				}

				ok_Hash.put("tMap_1", true);
				end_Hash.put("tMap_1", System.currentTimeMillis());

				/**
				 * [tMap_1 end ] stop
				 */

				/**
				 * [tHDFSOutput_1 end ] start
				 */

				currentComponent = "tHDFSOutput_1";

				if (outtHDFSOutput_1 != null) {
					outtHDFSOutput_1.close();
				}

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "rdv");
				}

				ok_Hash.put("tHDFSOutput_1", true);
				end_Hash.put("tHDFSOutput_1", System.currentTimeMillis());

				if (execStat) {
					runStat.updateStatOnConnection("OnComponentOk1", 0, "ok");
				}
				tDBClose_1Process(globalMap);

				/**
				 * [tHDFSOutput_1 end ] stop
				 */

				/**
				 * [tLogRow_1 end ] start
				 */

				currentComponent = "tLogRow_1";

//////

				java.io.PrintStream consoleOut_tLogRow_1 = null;
				if (globalMap.get("tLogRow_CONSOLE") != null) {
					consoleOut_tLogRow_1 = (java.io.PrintStream) globalMap.get("tLogRow_CONSOLE");
				} else {
					consoleOut_tLogRow_1 = new java.io.PrintStream(new java.io.BufferedOutputStream(System.out));
					globalMap.put("tLogRow_CONSOLE", consoleOut_tLogRow_1);
				}

				consoleOut_tLogRow_1.println(util_tLogRow_1.format().toString());
				consoleOut_tLogRow_1.flush();
//////
				globalMap.put("tLogRow_1_NB_LINE", nb_line_tLogRow_1);

///////////////////////    			

				if (execStat) {
					runStat.updateStat(resourceMap, iterateId, 2, 0, "row2");
				}

				ok_Hash.put("tLogRow_1", true);
				end_Hash.put("tLogRow_1", System.currentTimeMillis());

				/**
				 * [tLogRow_1 end ] stop
				 */

			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tDBInput_2 finally ] start
				 */

				currentComponent = "tDBInput_2";

				/**
				 * [tDBInput_2 finally ] stop
				 */

				/**
				 * [tMap_1 finally ] start
				 */

				currentComponent = "tMap_1";

				/**
				 * [tMap_1 finally ] stop
				 */

				/**
				 * [tHDFSOutput_1 finally ] start
				 */

				currentComponent = "tHDFSOutput_1";

				/**
				 * [tHDFSOutput_1 finally ] stop
				 */

				/**
				 * [tLogRow_1 finally ] start
				 */

				currentComponent = "tLogRow_1";

				/**
				 * [tLogRow_1 finally ] stop
				 */

			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tDBInput_2_SUBPROCESS_STATE", 1);
	}

	public void tDBClose_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
		globalMap.put("tDBClose_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tDBClose_1 begin ] start
				 */

				ok_Hash.put("tDBClose_1", false);
				start_Hash.put("tDBClose_1", System.currentTimeMillis());

				currentComponent = "tDBClose_1";

				int tos_count_tDBClose_1 = 0;

				/**
				 * [tDBClose_1 begin ] stop
				 */

				/**
				 * [tDBClose_1 main ] start
				 */

				currentComponent = "tDBClose_1";

				java.sql.Connection conn_tDBClose_1 = (java.sql.Connection) globalMap.get("conn_tDBConnection_2");
				if (conn_tDBClose_1 != null && !conn_tDBClose_1.isClosed()) {
					conn_tDBClose_1.close();
				}

				tos_count_tDBClose_1++;

				/**
				 * [tDBClose_1 main ] stop
				 */

				/**
				 * [tDBClose_1 process_data_begin ] start
				 */

				currentComponent = "tDBClose_1";

				/**
				 * [tDBClose_1 process_data_begin ] stop
				 */

				/**
				 * [tDBClose_1 process_data_end ] start
				 */

				currentComponent = "tDBClose_1";

				/**
				 * [tDBClose_1 process_data_end ] stop
				 */

				/**
				 * [tDBClose_1 end ] start
				 */

				currentComponent = "tDBClose_1";

				ok_Hash.put("tDBClose_1", true);
				end_Hash.put("tDBClose_1", System.currentTimeMillis());

				/**
				 * [tDBClose_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tDBClose_1 finally ] start
				 */

				currentComponent = "tDBClose_1";

				/**
				 * [tDBClose_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tDBClose_1_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHDFSConnection_2Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHDFSConnection_2_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHDFSConnection_2", false);
				start_Hash.put("tHadoopConfManager_tHDFSConnection_2", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHDFSConnection_2";

				int tos_count_tHadoopConfManager_tHDFSConnection_2 = 0;

				String libPath_tHadoopConfManager_tHDFSConnection_2 = "";

				class DealJobLibrary_tHadoopConfManager_tHDFSConnection_2 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHDFSConnection_2 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHDFSConnection_2();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-CHU_Cluster.jar", this.contextStr);

				libPath_tHadoopConfManager_tHDFSConnection_2 = new java.io.File(
						"C:/TOS_BD-20200219_1130-V7.3.1/workspace/CHU/temp/lib/" + confJarName).getAbsolutePath();
				libPath_tHadoopConfManager_tHDFSConnection_2 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHDFSConnection_2);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHDFSConnection_2 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHDFSConnection_2 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHDFSConnection_2.setAccessible(true);
				method_tHadoopConfManager_tHDFSConnection_2.invoke(currentLoadertHadoopConfManager_tHDFSConnection_2,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHDFSConnection_2).toURL() });

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSConnection_2";

				tos_count_tHadoopConfManager_tHDFSConnection_2++;

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSConnection_2";

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSConnection_2";

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSConnection_2";

				ok_Hash.put("tHadoopConfManager_tHDFSConnection_2", true);
				end_Hash.put("tHadoopConfManager_tHDFSConnection_2", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSConnection_2";

				/**
				 * [tHadoopConfManager_tHDFSConnection_2 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHDFSConnection_2_SUBPROCESS_STATE", 1);
	}

	public void tHadoopConfManager_tHDFSOutput_1Process(final java.util.Map<String, Object> globalMap)
			throws TalendException {
		globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", 0);

		final boolean execStat = this.execStat;

		String iterateId = "";

		String currentComponent = "";
		java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

		try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { // start the resume
				globalResumeTicket = true;

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 begin ] start
				 */

				ok_Hash.put("tHadoopConfManager_tHDFSOutput_1", false);
				start_Hash.put("tHadoopConfManager_tHDFSOutput_1", System.currentTimeMillis());

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				int tos_count_tHadoopConfManager_tHDFSOutput_1 = 0;

				String libPath_tHadoopConfManager_tHDFSOutput_1 = "";

				class DealJobLibrary_tHadoopConfManager_tHDFSOutput_1 {

					public String getConfJarName(String confLib, String extraId) {
						String confJarName = confLib;
						if (extraId != null && extraId.length() > 0) {
							String jarName = confLib.substring(0, confLib.lastIndexOf("."));
							String jarExt = confLib.substring(confLib.lastIndexOf("."));
							confJarName = jarName + "_" + extraId + jarExt;
						}
						return confJarName;
					}

					public String replaceJarPathsFromCrcMap(String originalClassPathLine) throws java.lang.Exception {
						String classPathLine = "";
						String crcMapPath = new java.io.File("../crcMap").getCanonicalPath();
						if (isNeedAddLibsPath(crcMapPath)) {
							java.util.Map<String, String> crcMap = null;
							java.io.ObjectInputStream ois = new java.io.ObjectInputStream(
									new java.io.FileInputStream(crcMapPath));
							crcMap = (java.util.Map<String, String>) ois.readObject();
							ois.close();
							classPathLine = addLibsPath(originalClassPathLine, crcMap);
						} else {
							classPathLine = originalClassPathLine;
						}
						return classPathLine;
					}

					private boolean isNeedAddLibsPath(String crcMapPath) {
						if (!(new java.io.File(crcMapPath).exists())) {// when not use cache
							return false;
						}
						return true;
					}

					private String addLibsPath(String line, java.util.Map<String, String> crcMap) {
						for (java.util.Map.Entry<String, String> entry : crcMap.entrySet()) {
							line = adaptLibPaths(line, entry);
						}
						return line;
					}

					private String adaptLibPaths(String line, java.util.Map.Entry<String, String> entry) {
						String jarName = entry.getValue();
						String crc = entry.getKey();
						String libStringFinder = "../lib/" + jarName;
						if (line.contains(libStringFinder)) {
							line = line.replace(libStringFinder, "../../../cache/lib/" + crc + "/" + jarName);
						} else if (line.contains(":$ROOT_PATH/" + jarName + ":")) {
							line = line.replace(":$ROOT_PATH/" + jarName + ":",
									":$ROOT_PATH/../../../cache/lib/" + crc + "/" + jarName + ":");
						} else if (line.contains(";" + jarName + ";")) {
							line = line.replace(";" + jarName + ";",
									";../../../cache/lib/" + crc + "/" + jarName + ";");
						}
						return line;
					}

				}

				DealJobLibrary_tHadoopConfManager_tHDFSOutput_1 dealJobLibrary = new DealJobLibrary_tHadoopConfManager_tHDFSOutput_1();
				String confJarName = dealJobLibrary.getConfJarName("hadoop-conf-CHU_Cluster.jar", this.contextStr);

				libPath_tHadoopConfManager_tHDFSOutput_1 = new java.io.File(
						"C:/TOS_BD-20200219_1130-V7.3.1/workspace/CHU/temp/lib/" + confJarName).getAbsolutePath();
				libPath_tHadoopConfManager_tHDFSOutput_1 = dealJobLibrary
						.replaceJarPathsFromCrcMap(libPath_tHadoopConfManager_tHDFSOutput_1);

				java.net.URLClassLoader currentLoadertHadoopConfManager_tHDFSOutput_1 = (java.net.URLClassLoader) Thread
						.currentThread().getContextClassLoader();
				java.lang.reflect.Method method_tHadoopConfManager_tHDFSOutput_1 = java.net.URLClassLoader.class
						.getDeclaredMethod("addURL", new Class[] { java.net.URL.class });
				method_tHadoopConfManager_tHDFSOutput_1.setAccessible(true);
				method_tHadoopConfManager_tHDFSOutput_1.invoke(currentLoadertHadoopConfManager_tHDFSOutput_1,
						new Object[] { new java.io.File(libPath_tHadoopConfManager_tHDFSOutput_1).toURL() });

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 main ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				tos_count_tHadoopConfManager_tHDFSOutput_1++;

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 main ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_begin ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_begin ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 process_data_end ] stop
				 */

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 end ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				ok_Hash.put("tHadoopConfManager_tHDFSOutput_1", true);
				end_Hash.put("tHadoopConfManager_tHDFSOutput_1", System.currentTimeMillis());

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 end ] stop
				 */
			} // end the resume

		} catch (java.lang.Exception e) {

			TalendException te = new TalendException(e, currentComponent, globalMap);

			throw te;
		} catch (java.lang.Error error) {

			runStat.stopThreadStat();

			throw error;
		} finally {

			try {

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 finally ] start
				 */

				currentComponent = "tHadoopConfManager_tHDFSOutput_1";

				/**
				 * [tHadoopConfManager_tHDFSOutput_1 finally ] stop
				 */
			} catch (java.lang.Exception e) {
				// ignore
			} catch (java.lang.Error error) {
				// ignore
			}
			resourceMap = null;
		}

		globalMap.put("tHadoopConfManager_tHDFSOutput_1_SUBPROCESS_STATE", 1);
	}

	public String resuming_logs_dir_path = null;
	public String resuming_checkpoint_path = null;
	public String parent_part_launcher = null;
	private String resumeEntryMethodName = null;
	private boolean globalResumeTicket = false;

	public boolean watch = false;
	// portStats is null, it means don't execute the statistics
	public Integer portStats = null;
	public int portTraces = 4334;
	public String clientHost;
	public String defaultClientHost = "localhost";
	public String contextStr = "Default";
	public boolean isDefaultContext = true;
	public String pid = "0";
	public String rootPid = null;
	public String fatherPid = null;
	public String fatherNode = null;
	public long startTime = 0;
	public boolean isChildJob = false;
	public String log4jLevel = "";

	private boolean enableLogStash;

	private boolean execStat = true;

	private ThreadLocal<java.util.Map<String, String>> threadLocal = new ThreadLocal<java.util.Map<String, String>>() {
		protected java.util.Map<String, String> initialValue() {
			java.util.Map<String, String> threadRunResultMap = new java.util.HashMap<String, String>();
			threadRunResultMap.put("errorCode", null);
			threadRunResultMap.put("status", "");
			return threadRunResultMap;
		};
	};

	private PropertiesWithType context_param = new PropertiesWithType();
	public java.util.Map<String, Object> parentContextMap = new java.util.HashMap<String, Object>();

	public String status = "";

	public static void main(String[] args) {
		final Dim_RDV Dim_RDVClass = new Dim_RDV();

		int exitCode = Dim_RDVClass.runJobInTOS(args);

		System.exit(exitCode);
	}

	public String[][] runJob(String[] args) {

		int exitCode = runJobInTOS(args);
		String[][] bufferValue = new String[][] { { Integer.toString(exitCode) } };

		return bufferValue;
	}

	public boolean hastBufferOutputComponent() {
		boolean hastBufferOutput = false;

		return hastBufferOutput;
	}

	public int runJobInTOS(String[] args) {
		// reset status
		status = "";

		String lastStr = "";
		for (String arg : args) {
			if (arg.equalsIgnoreCase("--context_param")) {
				lastStr = arg;
			} else if (lastStr.equals("")) {
				evalParam(arg);
			} else {
				evalParam(lastStr + " " + arg);
				lastStr = "";
			}
		}
		enableLogStash = "true".equalsIgnoreCase(System.getProperty("monitoring"));

		if (clientHost == null) {
			clientHost = defaultClientHost;
		}

		if (pid == null || "0".equals(pid)) {
			pid = TalendString.getAsciiRandomString(6);
		}

		if (rootPid == null) {
			rootPid = pid;
		}
		if (fatherPid == null) {
			fatherPid = pid;
		} else {
			isChildJob = true;
		}

		if (portStats != null) {
			// portStats = -1; //for testing
			if (portStats < 0 || portStats > 65535) {
				// issue:10869, the portStats is invalid, so this client socket can't open
				System.err.println("The statistics socket port " + portStats + " is invalid.");
				execStat = false;
			}
		} else {
			execStat = false;
		}

		try {
			// call job/subjob with an existing context, like: --context=production. if
			// without this parameter, there will use the default context instead.
			java.io.InputStream inContext = Dim_RDV.class.getClassLoader()
					.getResourceAsStream("chu/dim_rdv_0_1/contexts/" + contextStr + ".properties");
			if (inContext == null) {
				inContext = Dim_RDV.class.getClassLoader()
						.getResourceAsStream("config/contexts/" + contextStr + ".properties");
			}
			if (inContext != null) {
				// defaultProps is in order to keep the original context value
				if (context != null && context.isEmpty()) {
					defaultProps.load(inContext);
					context = new ContextProperties(defaultProps);
				}

				inContext.close();
			} else if (!isDefaultContext) {
				// print info and job continue to run, for case: context_param is not empty.
				System.err.println("Could not find the context " + contextStr);
			}

			if (!context_param.isEmpty()) {
				context.putAll(context_param);
				// set types for params from parentJobs
				for (Object key : context_param.keySet()) {
					String context_key = key.toString();
					String context_type = context_param.getContextType(context_key);
					context.setContextType(context_key, context_type);

				}
			}
			class ContextProcessing {
				private void processContext_0() {
					context.setContextType("HDFS_Cluster_User", "id_String");
					context.HDFS_Cluster_User = (String) context.getProperty("HDFS_Cluster_User");
					context.setContextType("HDFS_Cluster_hadoopConfSpecificJar", "id_String");
					context.HDFS_Cluster_hadoopConfSpecificJar = (String) context
							.getProperty("HDFS_Cluster_hadoopConfSpecificJar");
					context.setContextType("HDFS_Cluster_NameNodeUri", "id_String");
					context.HDFS_Cluster_NameNodeUri = (String) context.getProperty("HDFS_Cluster_NameNodeUri");
					context.setContextType("PostgresSQL_Server", "id_String");
					context.PostgresSQL_Server = (String) context.getProperty("PostgresSQL_Server");
					context.setContextType("PostgresSQL_AdditionalParams", "id_String");
					context.PostgresSQL_AdditionalParams = (String) context.getProperty("PostgresSQL_AdditionalParams");
					context.setContextType("PostgresSQL_Schema", "id_String");
					context.PostgresSQL_Schema = (String) context.getProperty("PostgresSQL_Schema");
					context.setContextType("PostgresSQL_Port", "id_String");
					context.PostgresSQL_Port = (String) context.getProperty("PostgresSQL_Port");
					context.setContextType("PostgresSQL_Database", "id_String");
					context.PostgresSQL_Database = (String) context.getProperty("PostgresSQL_Database");
					context.setContextType("PostgresSQL_Login", "id_String");
					context.PostgresSQL_Login = (String) context.getProperty("PostgresSQL_Login");
					context.setContextType("PostgresSQL_Password", "id_Password");
					String pwd_PostgresSQL_Password_value = context.getProperty("PostgresSQL_Password");
					context.PostgresSQL_Password = null;
					if (pwd_PostgresSQL_Password_value != null) {
						if (context_param.containsKey("PostgresSQL_Password")) {// no need to decrypt if it come from
																				// program argument or parent job
																				// runtime
							context.PostgresSQL_Password = pwd_PostgresSQL_Password_value;
						} else if (!pwd_PostgresSQL_Password_value.isEmpty()) {
							try {
								context.PostgresSQL_Password = routines.system.PasswordEncryptUtil
										.decryptPassword(pwd_PostgresSQL_Password_value);
								context.put("PostgresSQL_Password", context.PostgresSQL_Password);
							} catch (java.lang.RuntimeException e) {
								// do nothing
							}
						}
					}
				}

				public void processAllContext() {
					processContext_0();
				}
			}

			new ContextProcessing().processAllContext();
		} catch (java.io.IOException ie) {
			System.err.println("Could not load context " + contextStr);
			ie.printStackTrace();
		}

		// get context value from parent directly
		if (parentContextMap != null && !parentContextMap.isEmpty()) {
			if (parentContextMap.containsKey("HDFS_Cluster_User")) {
				context.HDFS_Cluster_User = (String) parentContextMap.get("HDFS_Cluster_User");
			}
			if (parentContextMap.containsKey("HDFS_Cluster_hadoopConfSpecificJar")) {
				context.HDFS_Cluster_hadoopConfSpecificJar = (String) parentContextMap
						.get("HDFS_Cluster_hadoopConfSpecificJar");
			}
			if (parentContextMap.containsKey("HDFS_Cluster_NameNodeUri")) {
				context.HDFS_Cluster_NameNodeUri = (String) parentContextMap.get("HDFS_Cluster_NameNodeUri");
			}
			if (parentContextMap.containsKey("PostgresSQL_Server")) {
				context.PostgresSQL_Server = (String) parentContextMap.get("PostgresSQL_Server");
			}
			if (parentContextMap.containsKey("PostgresSQL_AdditionalParams")) {
				context.PostgresSQL_AdditionalParams = (String) parentContextMap.get("PostgresSQL_AdditionalParams");
			}
			if (parentContextMap.containsKey("PostgresSQL_Schema")) {
				context.PostgresSQL_Schema = (String) parentContextMap.get("PostgresSQL_Schema");
			}
			if (parentContextMap.containsKey("PostgresSQL_Port")) {
				context.PostgresSQL_Port = (String) parentContextMap.get("PostgresSQL_Port");
			}
			if (parentContextMap.containsKey("PostgresSQL_Database")) {
				context.PostgresSQL_Database = (String) parentContextMap.get("PostgresSQL_Database");
			}
			if (parentContextMap.containsKey("PostgresSQL_Login")) {
				context.PostgresSQL_Login = (String) parentContextMap.get("PostgresSQL_Login");
			}
			if (parentContextMap.containsKey("PostgresSQL_Password")) {
				context.PostgresSQL_Password = (java.lang.String) parentContextMap.get("PostgresSQL_Password");
			}
		}

		// Resume: init the resumeUtil
		resumeEntryMethodName = ResumeUtil.getResumeEntryMethodName(resuming_checkpoint_path);
		resumeUtil = new ResumeUtil(resuming_logs_dir_path, isChildJob, rootPid);
		resumeUtil.initCommonInfo(pid, rootPid, fatherPid, projectName, jobName, contextStr, jobVersion);

		List<String> parametersToEncrypt = new java.util.ArrayList<String>();
		parametersToEncrypt.add("PostgresSQL_Password");
		// Resume: jobStart
		resumeUtil.addLog("JOB_STARTED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "",
				"", "", "", "", resumeUtil.convertToJsonText(context, parametersToEncrypt));

		if (execStat) {
			try {
				runStat.openSocket(!isChildJob);
				runStat.setAllPID(rootPid, fatherPid, pid, jobName);
				runStat.startThreadStat(clientHost, portStats);
				runStat.updateStatOnJob(RunStat.JOBSTART, fatherNode);
			} catch (java.io.IOException ioException) {
				ioException.printStackTrace();
			}
		}

		java.util.concurrent.ConcurrentHashMap<Object, Object> concurrentHashMap = new java.util.concurrent.ConcurrentHashMap<Object, Object>();
		globalMap.put("concurrentHashMap", concurrentHashMap);

		long startUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
		long endUsedMemory = 0;
		long end = 0;

		startTime = System.currentTimeMillis();

		try {
			errorCode = null;
			tHadoopConfManager_tHDFSConnection_2Process(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_tHadoopConfManager_tHDFSConnection_2) {
			globalMap.put("tHadoopConfManager_tHDFSConnection_2_SUBPROCESS_STATE", -1);

			e_tHadoopConfManager_tHDFSConnection_2.printStackTrace();

		}

		this.globalResumeTicket = true;// to run tPreJob

		this.globalResumeTicket = false;// to run others jobs

		try {
			errorCode = null;
			tDBConnection_2Process(globalMap);
			if (!"failure".equals(status)) {
				status = "end";
			}
		} catch (TalendException e_tDBConnection_2) {
			globalMap.put("tDBConnection_2_SUBPROCESS_STATE", -1);

			e_tDBConnection_2.printStackTrace();

		}

		this.globalResumeTicket = true;// to run tPostJob

		end = System.currentTimeMillis();

		if (watch) {
			System.out.println((end - startTime) + " milliseconds");
		}

		endUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
		if (false) {
			System.out.println((endUsedMemory - startUsedMemory) + " bytes memory increase when running : Dim_RDV");
		}

		if (execStat) {
			runStat.updateStatOnJob(RunStat.JOBEND, fatherNode);
			runStat.stopThreadStat();
		}
		int returnCode = 0;
		if (errorCode == null) {
			returnCode = status != null && status.equals("failure") ? 1 : 0;
		} else {
			returnCode = errorCode.intValue();
		}
		resumeUtil.addLog("JOB_ENDED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "", "",
				"" + returnCode, "", "", "");

		return returnCode;

	}

	// only for OSGi env
	public void destroy() {
		closeSqlDbConnections();

	}

	private void closeSqlDbConnections() {
		try {
			Object obj_conn;
			obj_conn = globalMap.remove("conn_tDBConnection_2");
			if (null != obj_conn) {
				((java.sql.Connection) obj_conn).close();
			}
		} catch (java.lang.Exception e) {
		}
	}

	private java.util.Map<String, Object> getSharedConnections4REST() {
		java.util.Map<String, Object> connections = new java.util.HashMap<String, Object>();
		connections.put("conn_tDBConnection_2", globalMap.get("conn_tDBConnection_2"));

		return connections;
	}

	private void evalParam(String arg) {
		if (arg.startsWith("--resuming_logs_dir_path")) {
			resuming_logs_dir_path = arg.substring(25);
		} else if (arg.startsWith("--resuming_checkpoint_path")) {
			resuming_checkpoint_path = arg.substring(27);
		} else if (arg.startsWith("--parent_part_launcher")) {
			parent_part_launcher = arg.substring(23);
		} else if (arg.startsWith("--watch")) {
			watch = true;
		} else if (arg.startsWith("--stat_port=")) {
			String portStatsStr = arg.substring(12);
			if (portStatsStr != null && !portStatsStr.equals("null")) {
				portStats = Integer.parseInt(portStatsStr);
			}
		} else if (arg.startsWith("--trace_port=")) {
			portTraces = Integer.parseInt(arg.substring(13));
		} else if (arg.startsWith("--client_host=")) {
			clientHost = arg.substring(14);
		} else if (arg.startsWith("--context=")) {
			contextStr = arg.substring(10);
			isDefaultContext = false;
		} else if (arg.startsWith("--father_pid=")) {
			fatherPid = arg.substring(13);
		} else if (arg.startsWith("--root_pid=")) {
			rootPid = arg.substring(11);
		} else if (arg.startsWith("--father_node=")) {
			fatherNode = arg.substring(14);
		} else if (arg.startsWith("--pid=")) {
			pid = arg.substring(6);
		} else if (arg.startsWith("--context_type")) {
			String keyValue = arg.substring(15);
			int index = -1;
			if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
				if (fatherPid == null) {
					context_param.setContextType(keyValue.substring(0, index),
							replaceEscapeChars(keyValue.substring(index + 1)));
				} else { // the subjob won't escape the especial chars
					context_param.setContextType(keyValue.substring(0, index), keyValue.substring(index + 1));
				}

			}

		} else if (arg.startsWith("--context_param")) {
			String keyValue = arg.substring(16);
			int index = -1;
			if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
				if (fatherPid == null) {
					context_param.put(keyValue.substring(0, index), replaceEscapeChars(keyValue.substring(index + 1)));
				} else { // the subjob won't escape the especial chars
					context_param.put(keyValue.substring(0, index), keyValue.substring(index + 1));
				}
			}
		} else if (arg.startsWith("--log4jLevel=")) {
			log4jLevel = arg.substring(13);
		} else if (arg.startsWith("--monitoring") && arg.contains("=")) {// for trunjob call
			final int equal = arg.indexOf('=');
			final String key = arg.substring("--".length(), equal);
			System.setProperty(key, arg.substring(equal + 1));
		}
	}

	private static final String NULL_VALUE_EXPRESSION_IN_COMMAND_STRING_FOR_CHILD_JOB_ONLY = "<TALEND_NULL>";

	private final String[][] escapeChars = { { "\\\\", "\\" }, { "\\n", "\n" }, { "\\'", "\'" }, { "\\r", "\r" },
			{ "\\f", "\f" }, { "\\b", "\b" }, { "\\t", "\t" } };

	private String replaceEscapeChars(String keyValue) {

		if (keyValue == null || ("").equals(keyValue.trim())) {
			return keyValue;
		}

		StringBuilder result = new StringBuilder();
		int currIndex = 0;
		while (currIndex < keyValue.length()) {
			int index = -1;
			// judege if the left string includes escape chars
			for (String[] strArray : escapeChars) {
				index = keyValue.indexOf(strArray[0], currIndex);
				if (index >= 0) {

					result.append(keyValue.substring(currIndex, index + strArray[0].length()).replace(strArray[0],
							strArray[1]));
					currIndex = index + strArray[0].length();
					break;
				}
			}
			// if the left string doesn't include escape chars, append the left into the
			// result
			if (index < 0) {
				result.append(keyValue.substring(currIndex));
				currIndex = currIndex + keyValue.length();
			}
		}

		return result.toString();
	}

	public Integer getErrorCode() {
		return errorCode;
	}

	public String getStatus() {
		return status;
	}

	ResumeUtil resumeUtil = null;
}
/************************************************************************************************
 * 93673 characters generated by Talend Open Studio for Big Data on the 16 mai
 * 2022 22:47:54 CEST
 ************************************************************************************************/